{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Stitching pairs of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "from skimage import color, io, transform\n",
    "import scipy\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided code - nothing to change here\n",
    "\n",
    "\"\"\"\n",
    "Harris Corner Detector\n",
    "Usage: Call the function harris(filename) for corner detection\n",
    "Reference   (Code adapted from):\n",
    "             http://www.kaij.org/blog/?p=89\n",
    "             Kai Jiang - Harris Corner Detector in Python\n",
    "             \n",
    "\"\"\"\n",
    "from pylab import *\n",
    "from scipy import signal\n",
    "from scipy import *\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def harris(filename, min_distance = 10, threshold = 0.1):\n",
    "    \"\"\"\n",
    "    filename: Path of image file\n",
    "    threshold: (optional)Threshold for corner detection\n",
    "    min_distance : (optional)Minimum number of pixels separating \n",
    "     corners and image boundary\n",
    "    \"\"\"\n",
    "    im = np.array(Image.open(filename).convert(\"L\"))\n",
    "    harrisim = compute_harris_response(im)\n",
    "    filtered_coords = get_harris_points(harrisim,min_distance, threshold)\n",
    "    plot_harris_points(im, filtered_coords)\n",
    "\n",
    "def gauss_derivative_kernels(size, sizey=None):\n",
    "    \"\"\" returns x and y derivatives of a 2D \n",
    "        gauss kernel array for convolutions \"\"\"\n",
    "    size = int(size)\n",
    "    if not sizey:\n",
    "        sizey = size\n",
    "    else:\n",
    "        sizey = int(sizey)\n",
    "    y, x = mgrid[-size:size+1, -sizey:sizey+1]\n",
    "    #x and y derivatives of a 2D gaussian with standard dev half of size\n",
    "    # (ignore scale factor)\n",
    "    gx = - x * exp(-(x**2/float((0.5*size)**2)+y**2/float((0.5*sizey)**2))) \n",
    "    gy = - y * exp(-(x**2/float((0.5*size)**2)+y**2/float((0.5*sizey)**2))) \n",
    "    return gx,gy\n",
    "\n",
    "def gauss_kernel(size, sizey = None):\n",
    "    \"\"\" Returns a normalized 2D gauss kernel array for convolutions \"\"\"\n",
    "    size = int(size)\n",
    "    if not sizey:\n",
    "        sizey = size\n",
    "    else:\n",
    "        sizey = int(sizey)\n",
    "    x, y = mgrid[-size:size+1, -sizey:sizey+1]\n",
    "    g = exp(-(x**2/float(size)+y**2/float(sizey)))\n",
    "    return g / g.sum()\n",
    "\n",
    "def compute_harris_response(im):\n",
    "    \"\"\" compute the Harris corner detector response function \n",
    "        for each pixel in the image\"\"\"\n",
    "    #derivatives\n",
    "    gx,gy = gauss_derivative_kernels(3)\n",
    "    imx = signal.convolve(im,gx, mode='same')\n",
    "    imy = signal.convolve(im,gy, mode='same')\n",
    "    #kernel for blurring\n",
    "    gauss = gauss_kernel(3)\n",
    "    #compute components of the structure tensor\n",
    "    Wxx = signal.convolve(imx*imx,gauss, mode='same')\n",
    "    Wxy = signal.convolve(imx*imy,gauss, mode='same')\n",
    "    Wyy = signal.convolve(imy*imy,gauss, mode='same')   \n",
    "    #determinant and trace\n",
    "    Wdet = Wxx*Wyy - Wxy**2\n",
    "    Wtr = Wxx + Wyy   \n",
    "    return Wdet / Wtr\n",
    "\n",
    "def get_harris_points(harrisim, min_distance=10, threshold=0.1):\n",
    "    \"\"\" return corners from a Harris response image\n",
    "        min_distance is the minimum nbr of pixels separating \n",
    "        corners and image boundary\"\"\"\n",
    "    #find top corner candidates above a threshold\n",
    "    corner_threshold = max(harrisim.ravel()) * threshold\n",
    "    harrisim_t = (harrisim > corner_threshold) * 1    \n",
    "    #get coordinates of candidates\n",
    "    candidates = harrisim_t.nonzero()\n",
    "    coords = [ (candidates[0][c],candidates[1][c]) for c in range(len(candidates[0]))]\n",
    "    #...and their values\n",
    "    candidate_values = [harrisim[c[0]][c[1]] for c in coords]    \n",
    "    #sort candidates\n",
    "    index = argsort(candidate_values)   \n",
    "    #store allowed point locations in array\n",
    "    allowed_locations = zeros(harrisim.shape)\n",
    "    allowed_locations[min_distance:-min_distance,min_distance:-min_distance] = 1   \n",
    "    #select the best points taking min_distance into account\n",
    "    filtered_coords = []\n",
    "    for i in index:\n",
    "        if allowed_locations[coords[i][0]][coords[i][1]] == 1:\n",
    "            filtered_coords.append(coords[i])\n",
    "            allowed_locations[(coords[i][0]-min_distance):(coords[i][0]+min_distance),\n",
    "                (coords[i][1]-min_distance):(coords[i][1]+min_distance)] = 0               \n",
    "    return filtered_coords\n",
    "\n",
    "def plot_harris_points(image, filtered_coords):\n",
    "    \"\"\" plots corners found in image\"\"\"\n",
    "    figure()\n",
    "    gray()\n",
    "    imshow(image)\n",
    "    plot([p[1] for p in filtered_coords],[p[0] for p in filtered_coords],'r*')\n",
    "    axis('off')\n",
    "    show()\n",
    "\n",
    "# Usage: \n",
    "#harris('./path/to/image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided code - nothing to change here\n",
    "\n",
    "def plot_inlier_matches(ax, img1, img2, inliers):\n",
    "    \"\"\"\n",
    "    Plot the matches between two images according to the matched keypoints\n",
    "    :param ax: plot handle\n",
    "    :param img1: left image\n",
    "    :param img2: right image\n",
    "    :inliers: x,y in the first image and x,y in the second image (Nx4)\n",
    "    \"\"\"\n",
    "    res = np.hstack([img1, img2])\n",
    "    ax.set_aspect('equal')\n",
    "    ax.imshow(res, cmap='gray')\n",
    "    \n",
    "    ax.plot(inliers[:,0], inliers[:,1], '+r')\n",
    "    ax.plot(inliers[:,2] + img1.shape[1], inliers[:,3], '+r')\n",
    "    ax.plot([inliers[:,0], inliers[:,2] + img1.shape[1]],\n",
    "            [inliers[:,1], inliers[:,3]], 'r', linewidth=0.4)\n",
    "    ax.axis('off')\n",
    "    \n",
    "# Usage:\n",
    "# fig, ax = plt.subplots(figsize=(20,10))\n",
    "# plot_inlier_matches(ax, img1, img2, computed_inliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See assignment page for the instructions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readimg(imgname):\n",
    "    img = cv2.imread(imgname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    return img\n",
    "\n",
    "def readimg_color(imgname):\n",
    "    img = cv2.imread(imgname)\n",
    "    img = cv2.normalize(img.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sift_descriptor(img):\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    kp, dsp = sift.detectAndCompute(img, None)\n",
    "\n",
    "    return kp, dsp\n",
    "\n",
    "def show_sift(kp, img):\n",
    "    # show the img with descriptors\n",
    "    copyimg = img.copy()\n",
    "    copyimg = cv2.drawKeypoints(img, kp, copyimg)\n",
    "    plt.imshow(copyimg)\n",
    "    plt.show()\n",
    "\n",
    "def calculate_distance(kp1, kp2, dsp1, dsp2, num_threshold):\n",
    "    # fast computation of Euclidean distance between each descriptors\n",
    "    dist = scipy.spatial.distance.cdist(dsp1, dsp2, 'sqeuclidean')\n",
    "    # find the matching coordinates\n",
    "    idx1 = np.where(dist < num_threshold)[0]\n",
    "    idx2 = np.where(dist < num_threshold)[1]\n",
    "    coord1 = np.array([kp1[idx].pt for idx in idx1])\n",
    "    coord2 = np.array([kp2[idx].pt for idx in idx2])\n",
    "    # put into pairs of coords\n",
    "    match_coords = np.concatenate((coord1, coord2), axis=1)\n",
    "\n",
    "    return match_coords\n",
    "\n",
    "def get_errors(matches, H):\n",
    "\t# difference between original img2 points and transformed img1 points with H\n",
    "    num_pairs = len(matches)\n",
    "    # all matching points in img1\n",
    "    p1 = np.concatenate((matches[:, 0:2], np.ones((1, num_pairs)).T), axis=1)\n",
    "    # all matching points in img2\n",
    "    p2 = matches[:, 2:4]\n",
    "\n",
    "    # Transform every point in p1 to estimate p2.\n",
    "    transformed_p1 = np.zeros((num_pairs, 2))\n",
    "    for i in range(num_pairs):\n",
    "        transformed_p1[i] = (np.matmul(H, p1[i]) / np.matmul(H, p1[i])[-1])[0:2]\n",
    "\n",
    "    # Compute error of each matching pair\n",
    "    errors = np.linalg.norm(p2 - transformed_p1, axis=1) ** 2\n",
    "    return errors\n",
    "\n",
    "def compute_H(subset):\n",
    "    # calculate the fitted homography\n",
    "    A = []\n",
    "\n",
    "    for i in range(subset.shape[0]):\n",
    "        p1 = np.append(subset[i][0:2], 1)\n",
    "        p2 = np.append(subset[i][2:4], 1)\n",
    "        \n",
    "        row1 = [0, 0, 0, p1[0], p1[1], p1[2], -p2[1]*p1[0], -p2[1]*p1[1], -p2[1]*p1[2]]\n",
    "        row2 = [p1[0], p1[1], p1[2], 0, 0, 0, -p2[0]*p1[0], -p2[0]*p1[1], -p2[0]*p1[2]]\n",
    "        A.append(row1)\n",
    "        A.append(row2)\n",
    "\n",
    "    A = np.array(A)\n",
    "\n",
    "    U, s, V = np.linalg.svd(A)\n",
    "    H = V[len(V)-1].reshape(3, 3)\n",
    "\n",
    "    # normalize\n",
    "    H = H / H[2, 2]\n",
    "    return H\n",
    "\n",
    "def show_inlier_matches(img1, img2, inliers):\n",
    "    print(\"num of inliers shown in the matching: \" + str(len(inliers)))\n",
    "    h1, w1 = img1.shape\n",
    "    h2, w2 = img2.shape\n",
    "\n",
    "    vis = np.zeros((max(h1, h2), w1 + w2), np.uint8)\n",
    "    vis[:, :w1] = img1\n",
    "    vis[:h2, w1:] = img2\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(vis)\n",
    "    ax.plot([inliers[:,0], inliers[:,2] + w1],[inliers[:,1], inliers[:,3]])\n",
    "    plt.show()\n",
    "\n",
    "def ransac(img1, img2, matches, thres_ransac):\n",
    "    itertimes = 1000\n",
    "    inliners = 0\n",
    "    max_inliners = 0\n",
    "\n",
    "    for iter in range(0, itertimes):\n",
    "        subset_idx = random.sample(range(matches.shape[0]), k=4)\n",
    "        subset = matches[subset_idx]\n",
    "\n",
    "        H = compute_H(subset)\n",
    "\n",
    "        # check if it is full rank\n",
    "        if np.linalg.matrix_rank(H) < 3:\n",
    "            continue\n",
    "\n",
    "        # the norm of error caused if we choose the above subset\n",
    "        errors = get_errors(matches, H)\n",
    "        idx = np.where(errors < thres_ransac)[0]\n",
    "        inlinerspts = matches[idx]\n",
    "\n",
    "        # find the best number of inliners \n",
    "        inliners = len(inlinerspts)\n",
    "        if inliners >= max_inliners:\n",
    "            which_inliners = inlinerspts.copy()\n",
    "            max_inliners = inliners\n",
    "            best_H = H.copy()\n",
    "            \n",
    "            avg_residual = sum(get_errors(matches[idx], H)) / inliners\n",
    "\n",
    "    print(\"num of inliners: \" + str(max_inliners) + \" average residual: \" + str(avg_residual))\n",
    "    show_inlier_matches(img1, img2, which_inliners)\n",
    "    return best_H\n",
    "\n",
    "# function provided by Maghav at Piazza @450\n",
    "def warp_images(image0, image1, H):\n",
    "    transform = skimage.transform.ProjectiveTransform(H)\n",
    "    warp = skimage.transform.warp\n",
    "\n",
    "    r, c = image1.shape[:2]\n",
    "    # Note that transformations take coordinates in (x, y) format,\n",
    "    # not (row, column), in order to be consistent with most literature\n",
    "    corners = np.array([[0, 0],\n",
    "                        [0, r],\n",
    "                        [c, 0],\n",
    "                        [c, r]])\n",
    "\n",
    "    # Warp the image corners to their new positions\n",
    "    warped_corners = transform(corners)\n",
    "\n",
    "    # Find the extents of both the reference image and the warped\n",
    "    # target image\n",
    "    all_corners = np.vstack((warped_corners, corners))\n",
    "\n",
    "    corner_min = np.min(all_corners, axis=0)\n",
    "    corner_max = np.max(all_corners, axis=0)\n",
    "\n",
    "    output_shape = (corner_max - corner_min)\n",
    "    output_shape = np.ceil(output_shape[::-1])\n",
    "\n",
    "    offset = skimage.transform.SimilarityTransform(translation=-corner_min)\n",
    "\n",
    "    image0_ = warp(image0, offset.inverse, output_shape=output_shape, cval=-1)\n",
    "\n",
    "    image1_ = warp(image1, (transform + offset).inverse, output_shape=output_shape, cval=-1)\n",
    "\n",
    "    image0_zeros = warp(image0, offset.inverse, output_shape=output_shape, cval=0)\n",
    "\n",
    "    image1_zeros = warp(image1, (transform + offset).inverse, output_shape=output_shape, cval=0)\n",
    "\n",
    "    overlap = (image0_ != -1.0 ).astype(int) + (image1_ != -1.0).astype(int)\n",
    "    overlap += (overlap < 1).astype(int)\n",
    "    merged = (image0_zeros+image1_zeros)/overlap\n",
    "\n",
    "    im = Image.fromarray((255*merged).astype('uint8'), mode='RGB')\n",
    "    im = np.asarray(im)\n",
    "\n",
    "    return im\n",
    "\n",
    "def main(leftimg, rightimg, leftimgcolor, rightimgcolor):\n",
    "    # using 7000, 0.5 for 2 pic; 9000, 1.0 for 3 pic\n",
    "    thres = 9000\n",
    "    thres_ransac = 1.0\n",
    "\n",
    "    kp1, dsp1 = sift_descriptor(leftimg)\n",
    "    kp2, dsp2 = sift_descriptor(rightimg)\n",
    "\n",
    "    # get all matching points\n",
    "    matches = calculate_distance(kp1, kp2, dsp1, dsp2, thres)\n",
    "\n",
    "    H_matrix = ransac(leftimg, rightimg, matches, thres_ransac)\n",
    "\n",
    "    stitched_img = warp_images(rightimgcolor, leftimgcolor, H_matrix)\n",
    "\n",
    "    return stitched_img\n",
    "\n",
    "def main_2pic():\n",
    "    dirs = 'MP3_part1_data/' + 'park/'\n",
    "    leftimg = readimg('left.jpg')\n",
    "    rightimg = readimg('right.jpg')\n",
    "    leftimgcolor = readimg_color('left.jpg')\n",
    "    rightimgcolor = readimg_color('right.jpg')\n",
    "\n",
    "    stitched_img = main(leftimg, rightimg, leftimgcolor, rightimgcolor)\n",
    "\n",
    "    plt.imshow(stitched_img)\n",
    "    plt.show()\n",
    "\n",
    "# def main_3pic():\n",
    "#     dirs = 'MP3_part1_data/' + 'pier/' # ledge pier hill\n",
    "#     leftimg = readimg(dirs, '1.jpg')\n",
    "#     midimg = readimg(dirs, '2.jpg')\n",
    "#     rightimg = readimg(dirs, '3.jpg')\n",
    "#     leftimgcolor = readimg_color(dirs, '1.jpg')\n",
    "#     midimgcolor = readimg_color(dirs, '2.jpg')\n",
    "#     rightimgcolor = readimg_color(dirs, '3.jpg')\n",
    "\n",
    "#     stitched1 = main(leftimg, midimg, leftimgcolor, midimgcolor)\n",
    "\n",
    "#     plt.imshow(stitched1)\n",
    "#     plt.show()\n",
    "\n",
    "#     grey_stitch1 = cv2.cvtColor(stitched1, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "#     stitched2 = main(grey_stitch1, rightimg, stitched1, rightimgcolor)\n",
    "\n",
    "#     plt.imshow(stitched2)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'xfeatures2d'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-58c0fcfa96b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain_2pic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-8a5e0a4834fa>\u001b[0m in \u001b[0;36mmain_2pic\u001b[1;34m()\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[0mrightimgcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreadimg_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'right.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m     \u001b[0mstitched_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleftimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrightimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleftimgcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrightimgcolor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstitched_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-8a5e0a4834fa>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(leftimg, rightimg, leftimgcolor, rightimgcolor)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[0mthres_ransac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m     \u001b[0mkp1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdsp1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msift_descriptor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleftimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m     \u001b[0mkp2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdsp2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msift_descriptor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrightimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-8a5e0a4834fa>\u001b[0m in \u001b[0;36msift_descriptor\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msift_descriptor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0msift\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxfeatures2d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSIFT_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mkp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdsp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msift\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mkp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdsp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'xfeatures2d'"
     ]
    }
   ],
   "source": [
    "main_2pic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
